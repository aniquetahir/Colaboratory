{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiAspectNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniquetahir/Colaboratory/blob/master/MultiAspectNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC9NNYtw6r9w",
        "colab_type": "code",
        "outputId": "d76eeb0f-1472-44d4-e9fd-16b366acd5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/pmin91/DS_projects.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DS_projects'...\n",
            "remote: Enumerating objects: 642, done.\u001b[K\n",
            "remote: Total 642 (delta 0), reused 0 (delta 0), pack-reused 642\u001b[K\n",
            "Receiving objects: 100% (642/642), 124.63 MiB | 25.62 MiB/s, done.\n",
            "Resolving deltas: 100% (290/290), done.\n",
            "Checking out files: 100% (298/298), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOoIVqwb6yFv",
        "colab_type": "code",
        "outputId": "d2b09e53-1d01-4947-cb05-9efb39713adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/DS_projects/04-Aspect_Based_Opinion_Mining/code"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DS_projects/04-Aspect_Based_Opinion_Mining/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Z-oKpD7Iyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "tree = ET.parse('../data/Restaurants_Train.xml')\n",
        "root = tree.getroot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh6BjWxr7KLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ByLySZE7ZUn",
        "colab_type": "code",
        "outputId": "53227cf8-aab7-4465-f331-52cea1def512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Use this dataframe for multilabel classification\n",
        "# Must use scikitlearn's multilabel binarizer\n",
        "\n",
        "labeled_reviews = []\n",
        "for sentence in root.findall(\"sentence\"):\n",
        "    entry = {}\n",
        "    aterms = []\n",
        "    aspects = []\n",
        "    if sentence.find(\"aspectTerms\"):\n",
        "        for aterm in sentence.find(\"aspectTerms\").findall(\"aspectTerm\"):\n",
        "            aterms.append(aterm.get(\"term\"))\n",
        "    if sentence.find(\"aspectCategories\"):\n",
        "        for aspect in sentence.find(\"aspectCategories\").findall(\"aspectCategory\"):\n",
        "            aspects.append(aspect.get(\"category\"))\n",
        "    entry[\"text\"], entry[\"terms\"], entry[\"aspects\"]= sentence[0].text, aterms, aspects\n",
        "    labeled_reviews.append(entry)\n",
        "labeled_df = pd.DataFrame(labeled_reviews)\n",
        "print(\"there are\",len(labeled_reviews),\"reviews in this training set\")\n",
        "#    print(sentence.find(\"aspectCategories\").findall(\"aspectCategory\").get(\"category\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 3044 reviews in this training set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km2PMs3w7cew",
        "colab_type": "code",
        "outputId": "1b8cb5c3-8a5e-4633-a6ee-d897d1117a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Save annotated reviews\n",
        "labeled_df.to_pickle(\"annotated_reviews_df.pkl\")\n",
        "labeled_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>terms</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>[staff]</td>\n",
              "      <td>[service]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "      <td>[food]</td>\n",
              "      <td>[food, anecdotes/miscellaneous]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "      <td>[food, kitchen, menu]</td>\n",
              "      <td>[food]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[service]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For those that go once and don't enjoy it, all...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[anecdotes/miscellaneous]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                          aspects\n",
              "0               But the staff was so horrible to us.  ...                        [service]\n",
              "1  To be completely fair, the only redeeming fact...  ...  [food, anecdotes/miscellaneous]\n",
              "2  The food is uniformly exceptional, with a very...  ...                           [food]\n",
              "3  Where Gabriela personaly greets you and recomm...  ...                        [service]\n",
              "4  For those that go once and don't enjoy it, all...  ...        [anecdotes/miscellaneous]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXnP63cx7ijf",
        "colab_type": "text"
      },
      "source": [
        "# Training the model with Naive Bayes\n",
        "1. replace pronouns with neural coref\n",
        "2. train the model with naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkAbiBv17pmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y neuralcoref\n",
        "!pip install --quiet neuralcoref --no-binary neuralcoref"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm5fQVVJ71wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y en-core-web-lg\n",
        "!pip uninstall -y spacy\n",
        "!pip install --quiet spacy==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llp1zBjQEO2C",
        "colab_type": "code",
        "outputId": "30bc3702-ae77-4b8f-e095-18c073a01789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=68a1dc3c928daea100a47422ba0a5b34f70f910d31049f291e8ac714f8d278c7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mso22wdc/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "  Found existing installation: en-core-web-lg 2.2.0\n",
            "    Uninstalling en-core-web-lg-2.2.0:\n",
            "      Successfully uninstalled en-core-web-lg-2.2.0\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRp1eHXd7esq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import neuralcoref\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "def replace_pronouns(text):\n",
        "    doc = nlp(text)\n",
        "    return doc._.coref_resolved"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-c9PLKL7nIO",
        "colab_type": "code",
        "outputId": "088b37d8-6f03-4165-a74f-a12518babf3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "annotated_reviews_df = pd.read_pickle(\"../pickled_files/annotated_reviews_df.pkl\")\n",
        "annotated_reviews_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspects</th>\n",
              "      <th>terms</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[service]</td>\n",
              "      <td>[staff]</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[food, anecdotes/miscellaneous]</td>\n",
              "      <td>[food]</td>\n",
              "      <td>To be completely fair, the only redeeming fact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[food]</td>\n",
              "      <td>[food, kitchen, menu]</td>\n",
              "      <td>The food is uniformly exceptional, with a very...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           aspects  ...                                               text\n",
              "0                        [service]  ...               But the staff was so horrible to us.\n",
              "1  [food, anecdotes/miscellaneous]  ...  To be completely fair, the only redeeming fact...\n",
              "2                           [food]  ...  The food is uniformly exceptional, with a very...\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJOovDRrBHu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new column for text whose pronouns have been replaced\n",
        "annotated_reviews_df[\"text_pro\"] = annotated_reviews_df.text.map(lambda x: replace_pronouns(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH7yPimcHUuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Convert the multi-labels into arrays\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(annotated_reviews_df.aspects)\n",
        "X = annotated_reviews_df.text_pro\n",
        "\n",
        "# Split data into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# save the the fitted binarizer labels\n",
        "# This is important: it contains the how the multi-label was binarized, so you need to\n",
        "# load this in the next folder in order to undo the transformation for the correct labels.\n",
        "filename = 'mlb.pkl'\n",
        "with open(filename, 'wb') as mlb_file:\n",
        "    pickle.dump(mlb, mlb_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTDyqEPjIyF0",
        "colab_type": "code",
        "outputId": "d819fa90-8817-4743-d6cb-f0282fea7676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install --quiet scikit-multilearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▊                            | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RcJZugYIh7B",
        "colab_type": "code",
        "outputId": "680ecbcf-e971-4013-a2d1-169b81e942d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "import numpy as np\n",
        "\n",
        "# LabelPowerset allows for multi-label classification\n",
        "# Build a pipeline for multinomial naive bayes classification\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
        "text_clf = text_clf.fit(X_train, y_train)\n",
        "predicted = text_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "np.mean(predicted == y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8651773981603154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8v23QhnIvBX",
        "colab_type": "code",
        "outputId": "ab041bff-6f2e-452f-af76-e0b8488df0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Test if SVM performs better\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', LabelPowerset(\n",
        "                             SGDClassifier(loss='hinge', penalty='l2',\n",
        "                                           alpha=1e-3, max_iter=6, random_state=42)))])\n",
        "_ = text_clf_svm.fit(X_train, y_train)\n",
        "predicted_svm = text_clf_svm.predict(X_test)\n",
        "\n",
        "#Calculate accuracy\n",
        "np.mean(predicted_svm == y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8670170827858081"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhyI_ni9JGS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# Train naive bayes on full dataset and save model\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
        "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
        "text_clf = text_clf.fit(X, y)\n",
        "\n",
        "# save the model to disk\n",
        "filename = 'naive_model1.pkl'\n",
        "with open(filename, 'wb') as model_file:\n",
        "    pickle.dump(text_clf, model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDIZRFoHJVE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mlb.inverse_transform(predicted)\n",
        "pred_df = pd.DataFrame(\n",
        "    {'text_pro': X_test,\n",
        "     'pred_category': mlb.inverse_transform(predicted)\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVm5pvjqJjmp",
        "colab_type": "code",
        "outputId": "685d56a9-537a-423c-f7a2-45721728584f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "pred_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_pro</th>\n",
              "      <th>pred_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>It's better than being on the roof of Sutton Place with 19 year old interns jabbing you in the ribs all night.</td>\n",
              "      <td>(anecdotes/miscellaneous,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1611</th>\n",
              "      <td>Don't expect to sit down inside though, there are only a few tables and they are always full.</td>\n",
              "      <td>(ambience,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2078</th>\n",
              "      <td>Again, if you are in this neighborhood - by all means, come here.</td>\n",
              "      <td>(anecdotes/miscellaneous,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>Go there to relax and feel like your somewhere else.</td>\n",
              "      <td>(anecdotes/miscellaneous,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2602</th>\n",
              "      <td>As far as the service goes, the waitresses were not particularly friendly, but the waitresses got the job done.</td>\n",
              "      <td>(service,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                             text_pro               pred_category\n",
              "453   It's better than being on the roof of Sutton Place with 19 year old interns jabbing you in the ribs all night.   (anecdotes/miscellaneous,)\n",
              "1611  Don't expect to sit down inside though, there are only a few tables and they are always full.                    (ambience,)               \n",
              "2078  Again, if you are in this neighborhood - by all means, come here.                                                (anecdotes/miscellaneous,)\n",
              "2715  Go there to relax and feel like your somewhere else.                                                             (anecdotes/miscellaneous,)\n",
              "2602  As far as the service goes, the waitresses were not particularly friendly, but the waitresses got the job done.  (service,)                "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3R9dPqxJl2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}